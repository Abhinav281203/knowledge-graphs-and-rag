{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45c2f89d-81dd-4af9-8c83-26b3ec1da8b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama_index\n",
      "  Downloading llama_index-0.8.50-py3-none-any.whl (791 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m791.3/791.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nebula3-python\n",
      "  Downloading nebula3_python-3.4.0-py3-none-any.whl (312 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.4/312.4 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting futures\n",
      "  Downloading futures-3.0.5.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting glob2\n",
      "  Downloading glob2-0.7.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pypdf\n",
      "  Downloading pypdf-3.16.4-py3-none-any.whl (276 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.6/276.6 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting SQLAlchemy[asyncio]>=1.4.49\n",
      "  Downloading SQLAlchemy-2.0.22-cp311-cp311-macosx_11_0_arm64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting dataclasses-json<0.6.0,>=0.5.7\n",
      "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
      "Collecting deprecated>=1.2.9.3\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain>=0.0.303\n",
      "  Downloading langchain-0.0.322-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama_index) (1.5.8)\n",
      "Collecting nltk<4.0.0,>=3.8.1\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy\n",
      "  Downloading numpy-1.26.1-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting openai>=0.26.4\n",
      "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading pandas-2.1.1-cp311-cp311-macosx_11_0_arm64.whl (10.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tenacity<9.0.0,>=8.2.0\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Collecting tiktoken>=0.3.3\n",
      "  Downloading tiktoken-0.5.1-cp311-cp311-macosx_11_0_arm64.whl (924 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m924.4/924.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting typing-extensions>=4.5.0\n",
      "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Collecting typing-inspect>=0.8.0\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting urllib3<2\n",
      "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httplib2>=0.20.0\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting future>=0.18.0\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.16.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nebula3-python) (1.16.0)\n",
      "Collecting pytz>=2021.1\n",
      "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.5/502.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting marshmallow<4.0.0,>=3.18.0\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wrapt<2,>=1.10\n",
      "  Downloading wrapt-1.15.0-cp311-cp311-macosx_11_0_arm64.whl (36 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2\n",
      "  Downloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain>=0.0.303->llama_index) (6.0.1)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Downloading aiohttp-3.8.6-cp311-cp311-macosx_11_0_arm64.whl (343 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.5/343.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting anyio<4.0\n",
      "  Downloading anyio-3.7.1-py3-none-any.whl (80 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jsonpatch<2.0,>=1.33\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.43\n",
      "  Downloading langsmith-0.0.51-py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydantic<3,>=1\n",
      "  Downloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain>=0.0.303->llama_index) (2.31.0)\n",
      "Collecting click\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting regex>=2021.8.3\n",
      "  Downloading regex-2023.10.3-cp311-cp311-macosx_11_0_arm64.whl (291 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.0/291.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting greenlet!=0.4.17\n",
      "  Downloading greenlet-3.0.0-cp311-cp311-macosx_10_9_universal2.whl (262 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.9/262.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mypy-extensions>=0.3.0\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->llama_index) (2.8.2)\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index) (3.3.1)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp311-cp311-macosx_11_0_arm64.whl (29 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp311-cp311-macosx_11_0_arm64.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.0-cp311-cp311-macosx_11_0_arm64.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from anyio<4.0->langchain>=0.0.303->llama_index) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from anyio<4.0->langchain>=0.0.303->llama_index) (1.3.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain>=0.0.303->llama_index) (2.4)\n",
      "Requirement already satisfied: packaging>=17.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->llama_index) (23.2)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Collecting pydantic-core==2.10.1\n",
      "  Downloading pydantic_core-2.10.1-cp311-cp311-macosx_11_0_arm64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2->langchain>=0.0.303->llama_index) (2023.7.22)\n",
      "Installing collected packages: pytz, glob2, futures, wrapt, urllib3, tzdata, typing-extensions, tqdm, tenacity, regex, pypdf, pyparsing, numpy, mypy-extensions, multidict, marshmallow, jsonpatch, joblib, greenlet, future, fsspec, frozenlist, click, async-timeout, anyio, annotated-types, yarl, typing-inspect, SQLAlchemy, pydantic-core, pandas, nltk, httplib2, deprecated, aiosignal, tiktoken, pydantic, nebula3-python, dataclasses-json, aiohttp, openai, langsmith, langchain, llama_index\n",
      "\u001b[33m  DEPRECATION: glob2 is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py install for glob2 ... \u001b[?25ldone\n",
      "\u001b[?25h\u001b[33m  DEPRECATION: futures is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py install for futures ... \u001b[?25ldone\n",
      "\u001b[?25h  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.0.7\n",
      "    Uninstalling urllib3-2.0.7:\n",
      "      Successfully uninstalled urllib3-2.0.7\n",
      "\u001b[33m  DEPRECATION: future is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py install for future ... \u001b[?25ldone\n",
      "\u001b[?25h  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 4.0.0\n",
      "    Uninstalling anyio-4.0.0:\n",
      "      Successfully uninstalled anyio-4.0.0\n",
      "Successfully installed SQLAlchemy-2.0.22 aiohttp-3.8.6 aiosignal-1.3.1 annotated-types-0.6.0 anyio-3.7.1 async-timeout-4.0.3 click-8.1.7 dataclasses-json-0.5.14 deprecated-1.2.14 frozenlist-1.4.0 fsspec-2023.10.0 future-0.18.3 futures-3.0.5 glob2-0.7 greenlet-3.0.0 httplib2-0.22.0 joblib-1.3.2 jsonpatch-1.33 langchain-0.0.322 langsmith-0.0.51 llama_index-0.8.50 marshmallow-3.20.1 multidict-6.0.4 mypy-extensions-1.0.0 nebula3-python-3.4.0 nltk-3.8.1 numpy-1.26.1 openai-0.28.1 pandas-2.1.1 pydantic-2.4.2 pydantic-core-2.10.1 pyparsing-3.1.1 pypdf-3.16.4 pytz-2023.3.post1 regex-2023.10.3 tenacity-8.2.3 tiktoken-0.5.1 tqdm-4.66.1 typing-extensions-4.8.0 typing-inspect-0.9.0 tzdata-2023.3 urllib3-1.26.18 wrapt-1.15.0 yarl-1.9.2\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install llama_index nebula3-python futures glob2 pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da0bbd0d-1626-41e4-b197-073309b1b4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7cbcc74-cf32-43ba-b79b-01e102e5cd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"EDENAI_API_KEY\"] = (\n",
    "    \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiNTM3ZWE2NWItZTZmZi00ZjQ3LThmY2QtNzU5NDg1YmRhNDMzIiwidHlwZSI6ImFwaV90b2tlbiJ9.NujKgo_tyy5V5SSP78F3s4_vY2Ll9afE578RAaSxKZ8\"\n",
    ")\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea7fb021-6b38-4ac4-9f49-3e9b29e3c099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import KnowledgeGraphIndex, LLMPredictor, ServiceContext\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index.graph_stores import NebulaGraphStore\n",
    "\n",
    "from langchain import OpenAI\n",
    "from langchain.llms import EdenAI\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a18cfb3f-71a2-4145-8c35-517d2bd4d7f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from llama_index import download_loader\n",
    "\n",
    "WikipediaReader = download_loader(\"WikipediaReader\")\n",
    "\n",
    "loader = WikipediaReader()\n",
    "\n",
    "documents = loader.load_data(\n",
    "    pages=[\"Demon Slayer: Kimetsu no Yaiba\"], auto_suggest=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "84387782-37cd-41b3-9d63-79933953c29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from glob import glob\n",
    "\n",
    "documents = []\n",
    "for item_path in glob(\"\" + \"*.pdf\"):\n",
    "    loader = PyPDFLoader(item_path)\n",
    "    documents.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "4e9a055f-f22d-4dd3-ac8f-191277316569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "48165f64-d8c4-4fde-a761-73e7e1a63c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='In a k ey step for locating important sentences, \\nNeATS computes the likelihood ratio λ \\n(Dunning, 1993) to identify key concepts in \\nunigrams, bigrams, and trigrams 1, using the \\non- topic document collection as the relevant \\nset and the off -topic document collection as the \\nirrelevant set.  Figure 1 shows the top 5 \\nconcepts with their relevancy scores ( -2λ) for \\nthe topic “ Slovenia Secession from \\nYugoslavia ” in the DUC -2001 test collection.  \\nThis is similar to the idea of topic signature \\nintroduced in (Lin and Hovy 2000 ). \\nWith the individual key concepts available, we \\nproceed to cluster these concepts in order to \\nidentify major subtopics within the main topic. \\nClusters are formed through strict lexical \\nconnection.  For example, Milan  and Kucan  \\nare grouped as “ Milan Kucan ” since “ Milan \\nKucan ” is a key bigram concept; while \\nCroatia, Yugoslavia , Slovenia , republic , and \\nare joined due to the connections as follows:  \\n• Slovenia Croatia  \\n• Croatia Slovenia  \\n• Yugoslavia Slovenia  \\n• republic Slovenia  \\n                                                 \\n1 Closed class words ( of, in, and, are , and so on) \\nwere ignored in constructing unigrams, bigrams and \\ntrigrams.  • Croatia republic  \\nEach sentence in the document set is  then \\nranked, using the key concept structures. An \\nexample is shown in Figure 2.  The ranking \\nalgorithm rewards most specific concepts first; \\nfor example, a sentence containing “ Milan \\nKucan ” has a higher score than a sentence \\ncontains only e ither Milan  or Kucan .  A \\nsentence containing both Milan  and Kucan  but \\nnot in consecutive order gets a lower score too.  \\nThis ranking algorithm performs relatively \\nwell, but it also results in many ties.  \\nTherefore, it is necessary to apply some \\nfiltering m echanism to maintain a reasonably \\nsized sentence pool for final presentation.  \\n2.2 Content Filtering  \\nNeATS uses three different filters: sentence \\nposition, stigma words, and maximum \\nmarginal relevancy.  \\n2.2.1  Sentence Position  \\nSentence position has been used as a goo d \\nimportant content filter since the late 60s \\n(Edmundson 1969).  It was also used as a \\nbaseline in a preliminary multi -document \\nsummarization study by Marcu and Gerber \\n(2001) with relatively good results.  We apply \\na simple sentence filter that only retain s the \\nlead 10 sentences.  \\n2.2.2  Stigma Words  \\nSome sentences start with  \\n• conjunctions (e.g., but, although , however ), \\n• the verb say and its derivatives,  \\n• quotation marks,  \\n• pronouns such as he, she , and they, \\nand usually cause discontinuity in summaries.  \\nSince we do n ot use discourse level selection \\ncriteria à la (Marcu 1999), we simply reduce \\nthe scores of these sentences to avoid including \\nthem in short summaries.  \\n2.2.3   Maximum Marginal Relevancy  Figure 2. Top 5 unigram, bigram, and trigram concepts for topic \"Slovenia Secession from Yugoslavia\".  Rank Unigram (-2l)Bigram (-2l)Trigram (-2l)\\n1Slovenia 319.48 federal army 21.27 Slovenia central bank 5.80\\n2Yugoslavia 159.55 Slovenia Croatia 19.33 minister foreign affairs 5.80\\n3Slovene 87.27 Milan Kucan 17.40 unallocated federal debt 5.80\\n4Croatia 79.48 European Community 13.53 Drnovsek prime minister 3.86\\n5Slovenian 67.82 foreign exchange 13.53 European Community countries 3.86\\nFigure 1. Sample key concept structure.  n1\\n(:SURF \"WEBCL-SUMMMARIZER-KUCAN\"\\n :CAT S-NP\\n :CLASS I-EN-WEBCL-SIGNATURE-KUCAN\\n :LEX  0.636363636363636\\n :SUBS\\n (((KUCAN-0)\\n   (:SURF \"Milan Kucan\"\\n    :CAT S-NP\\n    :CLASS I-EN-WEBCL-SIGNATURE-KUCAN\\n    :LEX 0.636363636363636\\n    :SUBS\\n    (((KUCAN-1)\\n      (:SURF \"Kucan\"\\n       :CAT S-NP\\n       :CLASS I-EN-WEBCL-SIGNATURE-KUCAN\\n       :LEX 0.636363636363636))\\n     ((KUCAN-2)\\n      (:SURF \"Milan\"\\n       :CAT S-NP\\n       :CLASS I-EN-WEBCL-SIGNATURE-KUCAN\\n       :LEX 0.636363636363636)))))))', metadata={'source': 'P02-1058.pdf', 'page': 1})"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7e1cf6c2-3d06-4fd3-98ae-9572753b4764",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = EdenAI(\n",
    "    provider=\"openai\", model=\"text-davinci-003\", temperature=0, max_tokens=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8d4e4aac-cdde-49ea-baf3-59c79729ef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_predictor = LLMPredictor(llm=llm)\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm_predictor=llm_predictor, chunk_size=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "0e4c19e1-02b6-40e6-a0bc-519385a38f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"NEBULA_USER\"] = \"root\"\n",
    "os.environ[\"NEBULA_PASSWORD\"] = \"nebula\"  # default password\n",
    "os.environ[\"NEBULA_ADDRESS\"] = (\n",
    "    \"127.0.0.1:9669\"  # assumed we have NebulaGraph installed locally\n",
    ")\n",
    "\n",
    "space_name = \"Demon\"\n",
    "edge_types, rel_prop_names = [\"relationship\"], [\n",
    "    \"relationship\"\n",
    "]  # default, could be omitted if created from an empty kg\n",
    "tags = [\"entity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "78faa15a-65dc-4f13-8f04-dcb45ace10df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(Demon Slayer: Kimetsu no Yaiba, is, Japanese manga series)\n",
      "(Demon Slayer: Kimetsu no Yaiba, has been published in, English)\n",
      "(Demon Slayer: Kimetsu no Yaiba, generated, estimated annual sales revenue of ¥1 trillion)\n",
      "\n",
      "(Tanjiro, unlocks, Hinokami Kagura)\n",
      "(Muzan, slaughters, Kamanue)\n",
      "(Nezuko, invulnerable to, sunlight)\n",
      "\n",
      "(Demon Slayer: Kimetsu no Yaiba, written and illustrated by, Koyoharu Gotouge)\n",
      "(Demon Slayer: Kimetsu no Yaiba, published in, Weekly Shōnen Jump)\n",
      "(Demon Slayer: Kimetsu no Yaiba, published in, Manga Plus)\n",
      "\n",
      "(Giyu Tomioka Gaiden, is, manga spin-off)\n",
      "(Kimetsu no Aima!, is, colored 4-koma spin-off)\n",
      "(Kimetsu Gakuen!, is, spin-off manga series)\n",
      "\n",
      "(Demon Slayer: Kimetsu no Yaiba Official Fanbook: Demon Slaying Corps Memorandum, released on, July 4, 2019)\n",
      "(Demon Slayer: Kimetsu no Yaiba Official Fanbook: Demon Slaying Corps Memorandum 2, released on, February 4, 2021)\n",
      "(Demon Slayer: Kimetsu no Yaiba – Koyoharu Gotouge Artbook: Ikuseisо, released on, February 4, 2021)\n",
      "\n",
      "(Anime, adapted by, Ufotable)\n",
      "(Anime, directed by, Haruo Sotozaki)\n",
      "(Anime, produced by, Hikaru Kondo)\n",
      "\n",
      "(Demon Slayer: Kimetsu no Yaiba, premiered in, Japan)\n",
      "(Demon Slayer: Kimetsu no Yaiba, grossed over, US$500 million)\n",
      "(Demon Slayer: Kimetsu no Yaiba, released worldwide digitally, June 22, 2021)\n",
      "\n",
      "(Yuki Kajiura, composed, anime music)\n",
      "(LiSA, performed, opening theme)\n",
      "(FictionJunction, performed, ending theme)\n",
      "\n",
      "(Demon Slayer: Kimetsu no Yaiba, generated, ¥1 trillion)\n",
      "(Demon Slayer: Kimetsu no Yaiba, won, Yahoo! Japan Search Awards)\n",
      "(Demon Slayer: Kimetsu no Yaiba, averaged, 18.43 million viewers)\n",
      "\n",
      "(Demon Slayer: Kimetsu no Yaiba, ranked, seventh on Top Anime & Manga Shows)\n",
      "(Demon Slayer: Kimetsu no Yaiba, won, Most Retweeted)\n",
      "(Demon Slayer: Kimetsu no Yaiba, increased, internal tourism)\n",
      "\n",
      "(Demon Slayer, sold, 40.3 million copies)\n",
      "(Demon Slayer, sold, 60.027 million physical print copies)\n",
      "(Demon Slayer, sold, 90.518 million physical print copies)\n",
      "\n",
      "(Demon Slayer: Kimetsu no Yaiba, recorded, over 120 million copies)\n",
      "(Demon Slayer: Kimetsu no Yaiba, sold, over 100 million copies)\n",
      "(Demon Slayer: Kimetsu no Yaiba, sold, over 29.5 million copies)\n",
      "\n",
      "(NPD BookScan, ranked, Demon Slayer: Kimetsu no Yaiba)\n",
      "(Nicholas Dupree, included, Demon Slayer: Kimetsu no Yaiba)\n",
      "(Rebecca Silverman, ranked, first volume)\n",
      "\n",
      "(Demon Slayer: Kimetsu no Yaiba, has, 11 awards)\n",
      "(Demon Slayer: Kimetsu no Yaiba, won, Grand Prix Award)\n",
      "(Demon Slayer: Kimetsu no Yaiba, won, New Face Award)\n",
      "\n",
      "(Demon Slayer: Kimetsu no Yaiba, official manga website at, Weekly Shōnen Jump)\n",
      "(Demon Slayer: Kimetsu no Yaiba, official manga English website at, Viz Media)\n",
      "(Demon Slayer: Kimetsu no Yaiba, official anime English website, )\n"
     ]
    }
   ],
   "source": [
    "graph_store = NebulaGraphStore(space_name=space_name)\n",
    "storage_context = StorageContext.from_defaults(graph_store=graph_store)\n",
    "\n",
    "\n",
    "# Creating KG\n",
    "index = KnowledgeGraphIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    "    service_context=service_context,\n",
    "    max_triplets_per_chunk=3,\n",
    "    space_name=space_name,\n",
    "    edge_types=edge_types,\n",
    "    rel_prop_names=rel_prop_names,\n",
    "    tags=tags,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7acadc9f-9316-457a-9fa2-8acd47449235",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    verbose=True,\n",
    "    retriever_mode=\"keyword\",\n",
    "    response_mode=\"tree_summarize\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2c5d705f-89ba-4e6a-95c6-c8048f2c0c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;32mExtracted keywords: ['Who', 'Tanjiro']\n",
      "\u001b[0mWARNING:llama_index.indices.knowledge_graph.retrievers:Index was not constructed with embeddings, skipping embedding usage...\n",
      "INFO:llama_index.indices.knowledge_graph.retrievers:> Querying with idx: 9248062f-a358-4e7a-911c-4389dd12ffbc: Continuing his missions, Tanjiro and Nezuko meet Zenitsu Agatsuma and Inosuke...\n",
      "\u001b[1;3;34mKG context:\n",
      "The following are knowledge sequence in max depth 2 in the form of directed graph like:\n",
      "`subject -[predicate]->, object, <-[predicate_next_hop]-, object_next_hop ...`\n",
      "Tanjiro{name: Tanjiro} -[relationship:{relationship: null, : null}]-> Hinokami Kagura{name: Hinokami Kagura}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Who is Tanjiro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "152d5310-704d-40b8-ba4a-947ddb382198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b> Tanjiro is a survivor of the exam who forms a team with Nezuko, Zenitsu Agatsuma, and Inosuke Hashibira. He unlocks a mysterious style called \"Hinokami Kagura\" and works alongside the Hashira. He learns his Hinokami Kagura is descended from the \"Sun Breathing\", the original breathing style invented by Yoriichi Tsugikuni, the most powerful Demon Slayer in history.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "020b2ea4-aa81-4ada-8ce7-1484d992c215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;32mExtracted keywords: ['enemies', 'Light']\n",
      "\u001b[0mWARNING:llama_index.indices.knowledge_graph.retrievers:Index was not constructed with embeddings, skipping embedding usage...\n",
      "INFO:llama_index.indices.knowledge_graph.retrievers:> Querying with idx: 11a0443d-0d34-4b46-a32d-ac97edf5e604: === Films ===\n",
      "Shusuke Kaneko, director of the film, intended for Light to app...\n",
      "INFO:llama_index.indices.knowledge_graph.retrievers:> Querying with idx: ed793aea-174e-4763-b367-e5e3a40f1617: == Reception ==\n",
      "\n",
      "\n",
      "=== Analysis ===\n",
      "Ohba described Light as a victim of the De...\n",
      "INFO:llama_index.indices.knowledge_graph.retrievers:> Querying with idx: f10c56a7-b53f-4937-8f07-03cb271a21d6: ==== American film ====\n",
      "Nat Wolff portrays \"Light Turner\": a Seattle high sch...\n",
      "\u001b[1;3;34mKG context:\n",
      "The following are knowledge sequence in max depth 2 in the form of directed graph like:\n",
      "`subject -[predicate]->, object, <-[predicate_next_hop]-, object_next_hop ...`\n",
      "Light{name: Light} -[relationship:{relationship: null, : null}]-> Death Note{name: Death Note} <-[relationship:{relationship: null, : null}]- Light Yagami{name: Light Yagami}\n",
      "Light{name: Light} -[relationship:{relationship: null, : null}]-> close relationship with father{name: close relationship with father}\n",
      "Light{name: Light} -[relationship:{relationship: null, : null}]-> Death Note{name: Death Note}\n",
      "Light{name: Light} -[relationship:{relationship: null, : null}]-> self-aggrandizing vision of justice{name: self-aggrandizing vision of justice}\n",
      "Light{name: Light} -[relationship:{relationship: null, : null}]-> warped desire{name: warped desire}\n",
      "Light{name: Light} <-[relationship:{relationship: null, : null}]- Tatsuya Fujiwara{name: Tatsuya Fujiwara} <-[relationship:{relationship: null, : null}]- Light Yagami{name: Light Yagami}\n",
      "Light{name: Light} <-[relationship:{relationship: null, : null}]- Tatsuya Fujiwara{name: Tatsuya Fujiwara}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Who are Light's enemies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bcd7f7ee-bd8d-4873-9734-6cdcce67d329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b> Light's enemies include L, James Turner, Mia Sutton, and Watari.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "8ad4e702-3ac3-4d87-973d-af457c925fbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ngql extension is already loaded. To reload it, use:\n",
      "  %reload_ext ngql\n",
      "Connection Pool Created\n",
      "INFO:nebula3.logger:Get connection to ('127.0.0.1', 9669)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name]\n",
       "Index: []"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip3 install ipython-ngql pyvis networkx\n",
    "%load_ext ngql\n",
    "%ngql --address 127.0.0.1 --port 9669 --user root --password nebula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "9cb20092-d2bd-4721-b277-a83944614dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('127.0.0.1', 9669)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(\"Tanjiro\" :entity{name: \"Tanjiro\"})-[:relatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(\"Tanjiro\" :entity{name: \"Tanjiro\"})-[:relatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(\"Tanjiro\" :entity{name: \"Tanjiro\"})-[:relatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(\"Tanjiro\" :entity{name: \"Tanjiro\"})-[:relatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(\"Tanjiro\" :entity{name: \"Tanjiro\"})-[:relatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(\"Tanjiro\" :entity{name: \"Tanjiro\"})-[:relatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(\"Tanjiro\" :entity{name: \"Tanjiro\"})-[:relatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(\"Tanjiro\" :entity{name: \"Tanjiro\"})&lt;-[:relati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(\"Tanjiro\" :entity{name: \"Tanjiro\"})&lt;-[:relati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(\"Tanjiro\" :entity{name: \"Tanjiro\"})-[:relatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(\"Tanjiro\" :entity{name: \"Tanjiro\"})-[:relatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(\"Tanjiro\" :entity{name: \"Tanjiro\"})-[:relatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(\"Tanjiro\" :entity{name: \"Tanjiro\"})&lt;-[:relati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(\"Demon Slayer\" :entity{name: \"Demon Slayer\"})...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(\"Demon Slayer\" :entity{name: \"Demon Slayer\"})...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(\"Demon Slayer\" :entity{name: \"Demon Slayer\"})...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(\"Demon Slayer\" :entity{name: \"Demon Slayer\"})...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(\"Demon Slayer\" :entity{name: \"Demon Slayer\"})...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(\"Demon Slayer\" :entity{name: \"Demon Slayer\"})...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(\"Demon Slayer\" :entity{name: \"Demon Slayer\"})...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(\"Demon Slayer\" :entity{name: \"Demon Slayer\"})...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(\"Demon Slayer\" :entity{name: \"Demon Slayer\"})...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(\"Demon Slayer\" :entity{name: \"Demon Slayer\"})...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(\"Demon Slayer\" :entity{name: \"Demon Slayer\"})...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(\"Demon Slayer\" :entity{name: \"Demon Slayer\"})...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(\"Nezuko\" :entity{name: \"Nezuko\"})-[:relations...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    p\n",
       "0   (\"Tanjiro\" :entity{name: \"Tanjiro\"})-[:relatio...\n",
       "1   (\"Tanjiro\" :entity{name: \"Tanjiro\"})-[:relatio...\n",
       "2   (\"Tanjiro\" :entity{name: \"Tanjiro\"})-[:relatio...\n",
       "3   (\"Tanjiro\" :entity{name: \"Tanjiro\"})-[:relatio...\n",
       "4   (\"Tanjiro\" :entity{name: \"Tanjiro\"})-[:relatio...\n",
       "5   (\"Tanjiro\" :entity{name: \"Tanjiro\"})-[:relatio...\n",
       "6   (\"Tanjiro\" :entity{name: \"Tanjiro\"})-[:relatio...\n",
       "7   (\"Tanjiro\" :entity{name: \"Tanjiro\"})<-[:relati...\n",
       "8   (\"Tanjiro\" :entity{name: \"Tanjiro\"})<-[:relati...\n",
       "9   (\"Tanjiro\" :entity{name: \"Tanjiro\"})-[:relatio...\n",
       "10  (\"Tanjiro\" :entity{name: \"Tanjiro\"})-[:relatio...\n",
       "11  (\"Tanjiro\" :entity{name: \"Tanjiro\"})-[:relatio...\n",
       "12  (\"Tanjiro\" :entity{name: \"Tanjiro\"})<-[:relati...\n",
       "13  (\"Demon Slayer\" :entity{name: \"Demon Slayer\"})...\n",
       "14  (\"Demon Slayer\" :entity{name: \"Demon Slayer\"})...\n",
       "15  (\"Demon Slayer\" :entity{name: \"Demon Slayer\"})...\n",
       "16  (\"Demon Slayer\" :entity{name: \"Demon Slayer\"})...\n",
       "17  (\"Demon Slayer\" :entity{name: \"Demon Slayer\"})...\n",
       "18  (\"Demon Slayer\" :entity{name: \"Demon Slayer\"})...\n",
       "19  (\"Demon Slayer\" :entity{name: \"Demon Slayer\"})...\n",
       "20  (\"Demon Slayer\" :entity{name: \"Demon Slayer\"})...\n",
       "21  (\"Demon Slayer\" :entity{name: \"Demon Slayer\"})...\n",
       "22  (\"Demon Slayer\" :entity{name: \"Demon Slayer\"})...\n",
       "23  (\"Demon Slayer\" :entity{name: \"Demon Slayer\"})...\n",
       "24  (\"Demon Slayer\" :entity{name: \"Demon Slayer\"})...\n",
       "25  (\"Nezuko\" :entity{name: \"Nezuko\"})-[:relations..."
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ngql\n",
    "USE Death;\n",
    "MATCH p=(n)-[*1..2]-()\n",
    "  WHERE id(n) IN [\"Demon Slayer\", \"Tanjiro\", \"Nezuko\"]\n",
    "RETURN p LIMIT 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "39e0b3e2-9ff1-445c-ae41-fd00b4c8c12f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500px\"\n",
       "            src=\"nebulagraph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1693cc1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<class 'pyvis.network.Network'> |N|=16 |E|=38"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ng_draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8b7142-1959-4c65-abef-8b275cbb6af8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202095c8-4ade-4568-b500-229c07780a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554cfef8-a30e-4101-b401-623dda2baff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
